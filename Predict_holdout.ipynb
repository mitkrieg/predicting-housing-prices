{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in hold out data, scalers, and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_holdout = pd.read_csv('data/kc_house_data_test_features.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "final_scaler = load(open('pickle/scaler.pickle','rb'))\n",
    "final_model = load(open('pickle/model.pickle','rb'))\n",
    "final_features = load(open('pickle/features.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering for holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we have to perform the same transformations on our holdout data (feature engineering, extreme values, and scaling) that we performed on the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capping bedrooms at 9\n",
    "houses_holdout.bedrooms = np.where(houses_holdout.bedrooms > 9, 9,houses_holdout.bedrooms)\n",
    "\n",
    "#capping bedrooms at 6\n",
    "houses_holdout.bathrooms = np.where(houses_holdout.bathrooms > 6, 6,houses_holdout.bathrooms)\n",
    "\n",
    "#capping sqft_living at 10,000\n",
    "houses_holdout.sqft_living = np.where(houses_holdout.sqft_living >10000,10000,houses_holdout.sqft_living)\n",
    "\n",
    "#capping sqft_lot at 95th percentile\n",
    "houses_holdout.sqft_lot = np.where(houses_holdout.sqft_lot >houses_holdout.sqft_lot.quantile(.95),\n",
    "                                 houses_holdout.sqft_lot.quantile(.95),houses_holdout.sqft_lot)\n",
    "\n",
    "#capping sqft_basement at 95th percentile\n",
    "houses_holdout.sqft_basement = np.where(houses_holdout.sqft_basement >houses_holdout.sqft_basement.quantile(.95),\n",
    "                                 houses_holdout.sqft_basement.quantile(.95),houses_holdout.sqft_basement)\n",
    "\n",
    "#capping sqft_lot15 at 95th percentile\n",
    "houses_holdout.sqft_lot15 = np.where(houses_holdout.sqft_lot15 >houses_holdout.sqft_lot15.quantile(.95),\n",
    "                                 houses_holdout.sqft_lot15.quantile(.95),houses_holdout.sqft_lot15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting `date` to Datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing date to datetime object\n",
    "import datetime as dt\n",
    "\n",
    "#Cut out timestamp\n",
    "houses_holdout['date'] = houses_holdout['date'].str.slice(stop=8)\n",
    "\n",
    "#convert to datetime\n",
    "houses_holdout['date'] = pd.to_datetime(houses_holdout['date'], errors='coerce', yearfirst=True)\n",
    "houses_holdout['month_sold'] = houses_holdout['date'].apply(lambda x:x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Years Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_holdout['yrs_old'] = houses_holdout.date.dt.year - houses_holdout.yr_built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Years since last renovation or build if not renovated:\n",
    "Making the year renovated feature more useful by identifying how long since the last renovation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_holdout['yrs_last_ren'] = houses_holdout.date.dt.year - houses_holdout.yr_renovated\n",
    "\n",
    "#replace new houses with renovation scores of zero\n",
    "conditions = [houses_holdout.yrs_last_ren == 2015,\n",
    "             houses_holdout.yrs_last_ren == 2014]\n",
    "choices = [0,0]\n",
    "houses_holdout['yrs_last_ren'] = np.select(conditions,choices,default=houses_holdout['yrs_last_ren'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renovated recently or not:\n",
    "Does a house that was renovated in the last 10 years have a differnce in price from those that were not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_holdout['renovated'] = np.where(houses_holdout.yr_renovated <= 10,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bedrooms per bathroom: \n",
    "This could indicate the number of people who have to share a bathroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_holdout['bed_per_bath'] = houses_holdout.bedrooms / houses_holdout.bathrooms\n",
    "\n",
    "#replace bed_per_bath scores with zero if divide by zerro error issue\n",
    "conditions = [houses_holdout.bed_per_bath == np.nan,\n",
    "             houses_holdout.bed_per_bath == np.inf,\n",
    "             houses_holdout.bed_per_bath.isna()]\n",
    "choices = [0,0,0]\n",
    "houses_holdout['bed_per_bath'] = np.select(conditions,choices,default=houses_holdout['bed_per_bath'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sqft_living per bedroom \n",
    "This could indicate the number of extra rooms (den, library, office, playroom, etc) or space shared per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_holdout['sqft_per_bed'] = houses_holdout.sqft_living / houses_holdout.bedrooms\n",
    "\n",
    "#replace bed_per_bath scores with zero if divide by zerro error issue\n",
    "conditions = [houses_holdout.sqft_per_bed == np.nan,\n",
    "             houses_holdout.sqft_per_bed == np.inf,\n",
    "             houses_holdout.sqft_per_bed.isna()]\n",
    "choices = [0,0,0]\n",
    "houses_holdout['sqft_per_bed'] = np.select(conditions,choices,default=houses_holdout['sqft_per_bed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Longitute & Latitude to identify City/Neighborhood:\n",
    "Most people don't think in zipcode or longitude/latitude but understand municipalities/neighborhoods to dictate how expensive a house should be. For example, in New York, it's commonly understood that Manhattan is more expensive area to live than the Bronx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverse_geocode\n",
    "\n",
    "#retreiving location dictionaries\n",
    "houses_holdout['location'] = reverse_geocode.search(list(zip(houses_holdout.lat,houses_holdout.long)))\n",
    "\n",
    "#islolating city specifically\n",
    "houses_holdout['city'] = houses_holdout['location'].apply(lambda x: x['city'])\n",
    "\n",
    "#Divide Seattle by zipcode to approximate urban/population dense areas/neighborhood differences\n",
    "houses_holdout['zipcode'] = houses_holdout['zipcode'].astype(str)\n",
    "houses_holdout['city'] = np.where(houses_holdout['city']=='Seattle','Seattle - ' + houses_holdout[\"zipcode\"],houses_holdout['city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dummy Variables For Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#encoder for dummy variables\n",
    "cat_encoder = OneHotEncoder()\n",
    "city_dummies = cat_encoder.fit_transform(houses_holdout[['city']])\n",
    "\n",
    "#turn spaces and dashes in column names to underscores\n",
    "city_names = []\n",
    "for city in cat_encoder.categories_[0].tolist():\n",
    "    city_names.append(city.replace(' ','_').replace('-','_'))\n",
    "\n",
    "#create dummy dataframe and concat with original dataframe\n",
    "dummy_df = pd.DataFrame(city_dummies.toarray(),columns=city_names)\n",
    "houses_holdout_dumb = pd.concat([houses_holdout,dummy_df],axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling Latitude/Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit scaler to training set\n",
    "#Set X to features\n",
    "X = houses_holdout_dumb[['lat','long']]\n",
    "\n",
    "#scale using stdScale\n",
    "X_scaled = final_scaler.transform(X)\n",
    "\n",
    "houses_holdout_dumb['stdscaled_lat'] = X_scaled[:, 0]\n",
    "houses_holdout_dumb['stdscaled_long'] = X_scaled[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Predict the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add cities not present in data\n",
    "houses_holdout_dumb['Maplewood'] = 0\n",
    "houses_holdout_dumb['Seattle___98106'] = 0\n",
    "houses_holdout_dumb['Southworth'] = 0\n",
    "houses_holdout_dumb['Riverbend'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([597881.50174867, 625072.41548459, 346458.85491639, ...,\n",
       "       347867.36083621, 454350.14411901, 354604.25734489])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = final_model.predict(houses_holdout_dumb[final_features])\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Export your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"housing_preds_Mitch_Krieger.csv\", final_pred, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
